# 讨论

## 5.1 RL 策略行为的生态学解释

RL 策略对状态变量敏感度弱，这并非算法失效，而是反映了：

- 种群自身具有较强的自然增长能力  
- 放飞与治理动作的影响有限  
- 环境随机性较高  
- Q 函数逼近器的分段常数特性  

当生态动力学远强于管理动作时，最优策略往往趋向节约成本、减少不必要的干预。

---

## 5.2 为什么种群如此稳定？

在校准环境中：

- 生存率适中  
- 繁殖率不低  
- 栖息地质量可恢复  

这些因素共同形成**正增长系统**。  
因此即使存在噪声，种群曲线仍然稳定向上。

---

## 5.3 灾害事件的主导作用

灾害发生概率为 3%：

- 期望每 33 年出现一次大规模死亡  
- 模拟轨迹中的大跌落恰好符合这一结构  

并且：

- RL 无法预测或避免灾害  
- 灾害无法通过管理动作缓解  
- 灾后恢复依赖系统自身的繁殖动力学

这些现象完全符合模型假设。

---

## 5.4 模型局限性

本项目的限制包括：

1. 铅风险模型简化，可能低估累积效应  
2. 栖息地指标 H 过于概念化，缺乏空间异质性  
3. 随机森林 Q 逼近器导致策略不连续  
4. 奖励函数未包含基因多样性、空间结构等生物学指标  
5. 神鹰的行为随机性未纳入模型  

这些局限不影响模型的方向性，但限制了现实适用性。

---

## 5.5 未来工作

未来可探索：

- 使用神经网络进行 Q 学习，提高策略连续性  
- 引入策略梯度或 actor-critic 框架  
- 同时优化成本、风险、遗传健康等多目标  
- 建立空间显式模型（metapopulation models）  
- 基于实地监测数据进行贝叶斯校准  

这些扩展将提升 RL 在野生动物管理中的实际应用潜力。
