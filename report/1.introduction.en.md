# Introduction

California condors (Gymnogyps californianus) represent one of the most critically endangered species in North America. Following near-extinction in the 1980s, recovery efforts have relied heavily on captive breeding, controlled releases, and an ongoing effort to mitigate anthropogenic mortality factors such as lead poisoning. Despite decades of conservation management, optimizing long-term population recovery strategies remains a significant challenge.

Traditional approaches to condor management rely on expert opinion, empirical rule-based policies, and mechanistic population models derived from biological literature. However, these methods struggle to adapt to environmental uncertainty, stochastic disaster events, and nonlinear population dynamics.

In recent years, reinforcement learning (RL) has emerged as a powerful framework for sequential decision-making under uncertainty. RL has demonstrated success in complex control problems, yet its application to ecological population management—particularly for endangered species—remains nascent.

This project explores the use of reinforcement learning to design long-term management strategies for the California condor population. We integrate:

- A calibrated age-structured population model  
- Historical survival and reproduction data  
- Stochastic dynamics including lead poisoning risk and disaster mortality  
- Fitted Q-Iteration (FQI) with Random Forest function approximation  
- Policy visualization tools (phase portraits, KDE distributions, and state-grid heatmaps)

We evaluate RL strategies against traditional literature-based policies and zero-intervention baselines to assess their biological realism and management effectiveness. This work provides both a computational framework and an ecological interpretation of RL-derived management policies.
